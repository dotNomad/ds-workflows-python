{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading data\n",
    "\n",
    "In this exercise we will cover how to use polars to read data from external data sources. To perform our analysis, we will need several different data sets:\n",
    "\n",
    "1. Vessel Verbose (`/Ferries/API/Vessels/rest/vesselverbose`): <https://www.wsdot.wa.gov/ferries/api/vessels/rest/help>\n",
    "2. Vessel History (`/Ferries/API/Vessels/rest/vesselhistory/{VesselName}/{DateStart}/{DateEnd}`): <https://www.wsdot.wa.gov/ferries/api/vessels/rest/help>\n",
    "3. Terminal Location (`/Ferries/API/terminals/rest/terminallocations`) <https://www.wsdot.wa.gov/Ferries/API/terminals/rest/help>\n",
    "4. Weather\n",
    "\n",
    "All data sets are hosted on <https://wsdot.wa.gov/traffic/api/>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 - read data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîÑ Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Download the **Vessel Verbose** data\n",
    "- Convert the data into a polars dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üßë‚Äçüíª Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The State of Washington data portal uses makes data available over an API. The API has lots of features, you can read more about how to use it here: <https://wsdot.wa.gov/traffic/api/>.\n",
    "\n",
    "To download the data, many persons first instinct is to download via:\n",
    "\n",
    "- Clicking through your web browser.\n",
    "- Via the curl command in the terminal.\n",
    "\n",
    "```bash\n",
    "WSDOT_ACCESS_CODE='xxxx-xxxx-xxxx-xxxx-xxxx'\n",
    "curl \"https://www.wsdot.wa.gov/Ferries/API/Vessels/rest/vesselverbose?apiaccesscode=${WSDOT_ACCESS_CODE}\"\n",
    "```\n",
    "\n",
    "There is a better way though! Using httpx we can download the data as JSON and then convert it into a Python dictionary. Then we use polars to create a DataFrame directly from the dictionary. First, lets download the data using httpx."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import httpx\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://www.wsdot.wa.gov/Ferries/API/Vessels/rest\"\n",
    "path = \"vesselverbose\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the API key from an environment variable.\n",
    "if Path(\".env\").exists():\n",
    "    load_dotenv()\n",
    "\n",
    "ws_dot_access_code = os.environ[\"WSDOT_ACCESS_CODE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our params in a dictionary.\n",
    "params = {\"apiaccesscode\": ws_dot_access_code}\n",
    "\n",
    "with httpx.Client(base_url=base_url, params=params) as client:\n",
    "    response = client.get(path)\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Response` object from httpx has several methods and attributes we can use to get more info about the request, and the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The URL that was used to make the request.\n",
    "response.url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The status of the response\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the response from JSON to a dictionary.\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many records are in the response.\n",
    "len(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the pprint function from rich for nicer formatting of the dictionary data.\n",
    "from rich.pretty import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(response.json()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we can use polars to convert the dictionary into a DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vessel_verbose_raw = pl.DataFrame(response.json())\n",
    "vessel_verbose_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 - write data to pin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîÑ Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Save `vessel_verbose_raw` to a Pin on Posit Connect.\n",
    "- This way, we do not need to hit the API every time we need to interact with the raw data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üßë‚Äçüíª Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the API key and server URL from an environment variable.\n",
    "if Path(\".env\").exists():\n",
    "    load_dotenv()\n",
    "\n",
    "connect_server = os.environ[\"CONNECT_SERVER\"]\n",
    "connect_api_key = os.environ[\"CONNECT_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a pins board.\n",
    "board = pins.board_connect(server_url=connect_server, api_key=connect_api_key)\n",
    "board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the username with your Posit Connect username.\n",
    "username = \"sam.edwardes\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reuse this data in future code we can use `board.pin_download` or `board.pin_read`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = board.pin_download(f\"{username}/vessel_verbose_raw\")\n",
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.read_parquet(paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3 - Get Other Data Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîÑ Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the following additional data sets:\n",
    "\n",
    "- **Vessel History**: the `https://www.wsdot.wa.gov/Ferries/API/Vessels/rest/vesselhistory` endpoint contains historical data about sailings.\n",
    "- **Terminal locations**: the `https://www.wsdot.wa.gov/Ferries/API/terminals/rest/terminallocations` endpoint contains information about ferry terminals locations.\n",
    "- **Weather data**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üßë‚Äçüíª Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vessel History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all of the vessel names\n",
    "base_url = \"https://www.wsdot.wa.gov/Ferries/API/Vessels/rest\"\n",
    "params = {\"apiaccesscode\": os.environ[\"WSDOT_ACCESS_CODE\"]}\n",
    "\n",
    "with httpx.Client(base_url=base_url, params=params) as client:\n",
    "    response = client.get(\"/vesselverbose\")\n",
    "\n",
    "vessel_names = [i[\"VesselName\"] for i in response.json()]\n",
    "vessel_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each vessel, get all of the history from the desired date range. Define\n",
    "# the start date and end date.\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = datetime.date(2020, 1, 1)\n",
    "start_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subtract 1 week from today, the Weather API has a 5 day delay.\n",
    "end_date = datetime.date.today() - datetime.timedelta(weeks=1)\n",
    "end_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the vessel history for each vessel.\n",
    "vessel_history_json = []\n",
    "\n",
    "for vessel_name in vessel_names:\n",
    "    print(f\"Getting vessel history for {vessel_name}...\")\n",
    "    with httpx.Client(base_url=base_url, params=params) as client:\n",
    "        response = client.get(\n",
    "            f\"/vesselhistory/{vessel_name}/{start_date}/{end_date}\", timeout=30\n",
    "        )\n",
    "\n",
    "    print(f\"\\t{len(response.json())} records retrieved for {vessel_name}.\")\n",
    "    vessel_history_json += response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many records were returned.\n",
    "f\"{len(vessel_history_json):,}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the first two records.\n",
    "vessel_history_json[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data from JSON to a polars DataFrame\n",
    "vessel_history_raw = pl.DataFrame(vessel_history_json)\n",
    "vessel_history_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data to Connect as a pin.\n",
    "board.pin_write(\n",
    "    vessel_history_raw.to_pandas(), f\"{username}/vessel_history_raw\", type=\"parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Terminal Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all of the terminal location data\n",
    "base_url = \"https://www.wsdot.wa.gov/Ferries/API/terminals/rest\"\n",
    "params = {\"apiaccesscode\": os.environ[\"WSDOT_ACCESS_CODE\"]}\n",
    "\n",
    "with httpx.Client(base_url=base_url, params=params) as client:\n",
    "    response = client.get(\"/terminallocations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many records were returned.\n",
    "f\"{len(response.json()):,}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the first two records.\n",
    "response.json()[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all of the terminal names\n",
    "{terminal[\"TerminalName\"]: terminal[\"TerminalAbbrev\"] for terminal in response.json()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terminal_locations_raw = pl.DataFrame(response.json())\n",
    "terminal_locations_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data to Connect as a pin.\n",
    "board.pin_write(\n",
    "    terminal_locations_raw.to_pandas(),\n",
    "    f\"{username}/terminal_locations_raw\",\n",
    "    type=\"parquet\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weather\n",
    "\n",
    "Get the weather data from <https://open-meteo.com/en/docs>. Here is an example URL:\n",
    "\n",
    "`https://api.open-meteo.com/v1/forecast?latitude=52.52&longitude=13.41&hourly=temperature_2m,precipitation,cloud_cover,visibility,wind_speed_10m`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get changes of of date ranges, starting from start_date.\n",
    "_start_date = start_date\n",
    "_end_date = start_date + datetime.timedelta(weeks=4)\n",
    "date_ranges = [(start_date, _end_date)]\n",
    "\n",
    "while True:\n",
    "    _start_date = _end_date + datetime.timedelta(days=1)\n",
    "    _end_date = min(_start_date + datetime.timedelta(weeks=4), end_date)\n",
    "    date_ranges.append((_start_date, _end_date))\n",
    "\n",
    "    if _end_date == end_date:\n",
    "        break\n",
    "\n",
    "date_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from typing import TypedDict\n",
    "\n",
    "base_url = \"https://archive-api.open-meteo.com/v1/\"\n",
    "\n",
    "\n",
    "class WeatherParams(TypedDict):\n",
    "    hourly: list[str]\n",
    "    latitude: float\n",
    "    longitude: float\n",
    "    start_date: datetime.date\n",
    "    end_date: datetime.date\n",
    "\n",
    "\n",
    "json_data = []\n",
    "\n",
    "with httpx.Client(base_url=base_url) as client:\n",
    "    for i in (\n",
    "        terminal_locations_raw.select(\"Latitude\", \"Longitude\", \"TerminalName\")\n",
    "        .to_pandas()\n",
    "        .to_dict(orient=\"records\")\n",
    "    ):\n",
    "        params[\"latitude\"] = round(i[\"Latitude\"], 2)\n",
    "        params[\"longitude\"] = round(i[\"Longitude\"], 2)\n",
    "\n",
    "        for date_range in date_ranges:\n",
    "            params: WeatherParams = {\n",
    "                \"hourly\": [\n",
    "                    \"weather_code\",\n",
    "                    \"temperature_2m\",\n",
    "                    \"precipitation\",\n",
    "                    \"cloud_cover\",\n",
    "                    \"wind_speed_10m\",\n",
    "                    \"wind_direction_10m\",\n",
    "                    \"wind_gusts_10m\",\n",
    "                ],\n",
    "                \"start_date\": date_range[0],\n",
    "                \"end_date\": date_range[1],\n",
    "                \"latitude\": round(i[\"Latitude\"], 2),\n",
    "                \"longitude\": round(i[\"Longitude\"], 2),\n",
    "            }\n",
    "\n",
    "            print(\n",
    "                f'Getting records for: {i[\"TerminalName\"]} <> {params[\"latitude\"]}, {params[\"longitude\"]} <> {params[\"start_date\"]} to {params[\"end_date\"]}...'\n",
    "            )\n",
    "\n",
    "            response = client.get(\"/archive\", params=params)\n",
    "\n",
    "            try:\n",
    "                print(response)\n",
    "                response.raise_for_status()\n",
    "                json_data.append(response.json())\n",
    "\n",
    "            except httpx.HTTPStatusError as exc:\n",
    "                if response.status_code == 429:\n",
    "                    print(\"Rate limit exceeded. Waiting 60 seconds...\")\n",
    "                    time.sleep(60)\n",
    "                    response = client.get(\"/forecast\", params=params)\n",
    "                    print(response)\n",
    "                    response.raise_for_status()\n",
    "                    json_data.append(response.json())\n",
    "                else:\n",
    "                    raise exc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terminal_weather = (\n",
    "    pl.DataFrame(json_data)\n",
    "    .unnest(\"hourly\")\n",
    "    .explode(\n",
    "        \"time\",\n",
    "        \"weather_code\",\n",
    "        \"temperature_2m\",\n",
    "        \"precipitation\",\n",
    "        \"cloud_cover\",\n",
    "        \"wind_speed_10m\",\n",
    "        \"wind_direction_10m\",\n",
    "        \"wind_gusts_10m\",\n",
    "    )\n",
    ")\n",
    "\n",
    "terminal_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data to Connect as a pin.\n",
    "board.pin_write(\n",
    "    terminal_weather.to_pandas(),\n",
    "    f\"{username}/terminal_weather_raw\",\n",
    "    type=\"parquet\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4 - Virtual environments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîÑ Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a virtual environment with venv.\n",
    "- Create a virtual environment with uv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üßë‚Äçüíª Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every content that you publish to Posit Connect should have its own virtual environment. This will allow us to define the minimum required dependencies that Connect will need to re-run this notebook. We have already define the dependencies in the `requirements.in` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "cat requirements.in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Virtual environments with venv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and activate a virtual environment with the following commands:\n",
    "\n",
    "```bash\n",
    "# Create virtual environment\n",
    "python3 -m venv .venv\n",
    "\n",
    "# Activate virtual environment\n",
    "source .venv/bin/activate\n",
    "\n",
    "# Update pip and \"friends\"\n",
    "python -m pip install --upgrade pip wheel setuptools\n",
    "\n",
    "# Install all of the requirements\n",
    "python -m pip install -r requirements.in\n",
    "\n",
    "# Capture all of the dependencies, including the transitive dependencies.\n",
    "python -m pip freeze > requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why do I use a `requirements.in` and a `requirements.txt`?\n",
    "\n",
    "- `requirements.in` is for humans. I create and maintain this file by hand. I use it to define the top level dependencies I want to bring into my project.\n",
    "- `requirements.txt` is for machines. I use this file to capture all of the dependencies, including the transitive dependencies. Posit Connect will use this file to install the dependencies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Virtual environments with uv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In 2024 an exciting new project called `uv` was released: https://github.com/astral-sh/uv.\n",
    "\n",
    "> n extremely fast Python package installer and resolver, written in Rust. Designed as a drop-in replacement for common pip and pip-tools workflows.\n",
    "\n",
    "I have started to adapt `uv` in my projects to replace pip because it is much faster, and has some features that are important to me (like syncing the `requirements.in` and `requirements.txt` files).\n",
    "\n",
    "First, deactivate and delete your existing virtual environment:\n",
    "\n",
    "```bash\n",
    "deactivate\n",
    "rm -rf .venv\n",
    "rm requirements.txt\n",
    "```\n",
    "\n",
    "Then, recreate it using `uv`:\n",
    "\n",
    "```bash\n",
    "# Create virtual environment\n",
    "uv venv\n",
    "\n",
    "# Activate virtual environment\n",
    "source .venv/bin/activate\n",
    "\n",
    "# Capture all of the dependencies, including the transitive dependencies.\n",
    "uv pip compile requirements.in --output-file requirements.txt\n",
    "\n",
    "# Install all of the requirements\n",
    "pip sync requirements.txt\n",
    "```\n",
    "\n",
    "In my daily workflow I use these two aliases everyday!\n",
    "\n",
    "```bash\n",
    "alias uvinit='uv venv && source .venv/bin/activate'\n",
    "alias uvsync='uv pip compile requirements.in --quiet --output-file requirements.txt && uv pip sync requirements.txt'\n",
    "```\n",
    "\n",
    "For more information on how I use `uv` check out this blog post: https://samedwardes.com/2024/04/21/python-uv-workflow/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5 - Publish the solution notebook to Connect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîÑ Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Publish the solution notebook to Posit Connect.\n",
    "- Share the notebook with the rest of the workshop.\n",
    "- Schedule the notebook to run once every week."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üßë‚Äçüíª Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following to deploy the notebook to Connect:\n",
    "\n",
    "```bash\n",
    "# Check that you have the required environment variables set\n",
    "echo $CONNECT_SERVER\n",
    "echo $CONNECT_API_KEY\n",
    "\n",
    "# Publish the notebook\n",
    "rsconnect deploy notebook --title \"Seattle Ferries - Raw data\" notebook.ipynb\n",
    "```\n",
    "\n",
    "After the deployment is successful:\n",
    "\n",
    "- Share the notebook with the person beside you.\n",
    "- Schedule the notebook to run once every week."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
