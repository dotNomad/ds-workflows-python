{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploration and validation\n",
    "\n",
    "In this exercise we will cover how to use Polars and Pandera to explore, tidy, and validate the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 - load data from Pin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîÑ Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use `polars` to load the data from Posit Connect into a Polars dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üßë‚Äçüíª Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import polars as pl\n",
    "from dotenv import load_dotenv\n",
    "import pins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the API key and server URL from an environment variable.\n",
    "if Path(\".env\").exists():\n",
    "    load_dotenv()\n",
    "\n",
    "connect_server = os.environ[\"CONNECT_SERVER\"]\n",
    "connect_api_key = os.environ[\"CONNECT_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a pins board.\n",
    "board = pins.board_connect(server_url=connect_server, api_key=connect_api_key)\n",
    "board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the username with your Posit Connect username.\n",
    "username = \"sam.edwardes\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the vessel verbose data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vessel_verbose_paths = board.pin_download(f\"{username}/vessel_verbose_raw\")\n",
    "vessel_verbose_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vessel_verbose = pl.read_parquet(vessel_verbose_paths)\n",
    "vessel_verbose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the vessel verbose history data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vessel_history_paths = board.pin_download(f\"{username}/vessel_history_raw\")\n",
    "vessel_history_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vessel_history = pl.read_parquet(vessel_history_paths)\n",
    "vessel_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 - explore the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîÑ Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin exploring the data. You will want to understand.\n",
    "\n",
    "- What columns exist in the data?\n",
    "- How do the two data sets relate to one another?\n",
    "- What is the type of each column (e.g. string, number, category, date)?\n",
    "- Which columns could be useful for the model.\n",
    "- What is the cardinality of categorical data?\n",
    "- Is all of the data in scope?\n",
    "- What steps will I need to perform to clean the data?\n",
    "\n",
    "**Tips**\n",
    "\n",
    "- Use VS Codes built in data viewer to explore the data.\n",
    "- If you are more comfortable with Pandas, you can convert the polars dataframe into a pandas dataframe (e.g. `df.to_pandas()`).\n",
    "- The polars user guide has great docs on how to use polars: https://docs.pola.rs.\n",
    "\n",
    "üö® We are not performing feature engineering at this stage. But it is a good time to start thinking about what features you can create from the data.\n",
    "\n",
    "> üí° We are not using it in this workshop, but `ydata-profiling` (<https://github.com/ydataai/ydata-profiling>) is a good tool for exploring a new dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üßë‚Äçüíª Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### vessel_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    vessel_history\n",
    "    .head(3)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The dates and times are not formatted correctly. We can fix this when we tidy the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### vessel_verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    vessel_verbose\n",
    "    .head(2)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many different vessels are in the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print more rows.\n",
    "pl.Config.set_tbl_rows(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    vessel_verbose\n",
    "    .select(pl.col('VesselID'), pl.col('VesselName'))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that each VesselID is unique.\n",
    "(\n",
    "    vessel_verbose\n",
    "    .get_column('VesselID')\n",
    "    .n_unique()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are all of the numerical columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(\n",
    "    vessel_verbose\n",
    "    .select(pl.selectors.numeric())\n",
    "    .head(5)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Some of the date based columns are integers or floats. During data tidying we could convert them into a proper date type.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are all of the string columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    vessel_verbose\n",
    "    .select(pl.selectors.string())\n",
    "    .head(5)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It looks like some missing values are represented with an empty string `\"\"` while others have a `null` value. We may want to make this consistent when we tidy the data.\n",
    "- Some string columns are measurements that should be converted into numeric types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much data is missing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    vessel_verbose\n",
    "    .null_count()\n",
    "    .transpose(include_header=True)\n",
    "    .rename({\"column\": \"Column Name\", \"column_0\": \"Missing Rows\"})\n",
    "    .with_columns(((pl.col(\"Missing Rows\") / vessel_verbose.shape[0]) * 100).round(1).alias('% Missing'))\n",
    "    .sort(\"Missing Rows\", descending=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whats in the `Class` column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    vessel_verbose\n",
    "    .get_column(\"Class\")\n",
    "    .head(2)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class column contains a `struct`: https://docs.pola.rs/user-guide/expressions/structs/\n",
    "\n",
    "> Polars `Structs` are the idiomatic way of working with multiple columns. It is also a free operation i.e. moving columns into Structs does not copy any data!\n",
    "\n",
    "Lets look more closely at the `Class` column for Cathlamet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    vessel_verbose\n",
    "    .filter(pl.col(\"VesselName\") == \"Cathlamet\")\n",
    "    .get_column(\"Class\")\n",
    "    .to_list()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the `Class` column contains a list with a single dictionary. When we tidy this data we can make it easier to work with by unnesting this data and moving it into its own columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3 - Tidy the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîÑ Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have a basic understanding of the data, the next step is to tidy the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üßë‚Äçüíª Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### vessel_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vessel_history.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the datetimes from strings to polars datetime objects. The logic is pretty complex. So we will abstract it into a function that we can apply to all of the required columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_string_to_datetime(series: pl.Series) -> pl.Series:\n",
    "    \"\"\"\n",
    "    Convert the datetime format from wadot into a datetime format that polars\n",
    "    can understand.\n",
    "\n",
    "    >>> convert_string_to_datetime(pl.Series(['/Date(1714547700000-0700)/']))\n",
    "    shape: (1,)\n",
    "    Series: '' [datetime[Œºs, UTC]]\n",
    "    [\n",
    "        2024-05-01 07:15:00 UTC\n",
    "    ]\n",
    "    \"\"\"\n",
    "    # Extract the unix time stamp. To work with polars we need the time\n",
    "    # the number of seconds since 1970-01-01 00:00 UTC, so divide by\n",
    "    # 1_000.\n",
    "    unix_timestamp = (\n",
    "        (series.str.extract(r\"/Date\\((\\d{13})[-+]\").cast(pl.Int64) / 1_000)\n",
    "        .cast(pl.Int64)\n",
    "        .cast(pl.String)\n",
    "    )\n",
    "    # Extract the timezone.\n",
    "    timezone = series.str.extract(r\"([-+]\\d{4})\")\n",
    "    # Create a new series that has the timestamp and timezone.\n",
    "    clean_timestamp = unix_timestamp + timezone\n",
    "    # Convert into a datetime.\n",
    "    datetime_series = clean_timestamp.str.to_datetime(\"%s%z\")\n",
    "    return datetime_series\n",
    "\n",
    "\n",
    "convert_string_to_datetime(pl.Series(['/Date(1714547700000-0700)/']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vessel_history_clean = (\n",
    "    vessel_history\n",
    "    .with_columns(\n",
    "        (\n",
    "            pl\n",
    "            .col(\"ScheduledDepart\", \"ActualDepart\", \"EstArrival\", \"Date\")\n",
    "            .map_batches(lambda s: convert_string_to_datetime(s)))\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vessel_history_clean.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### vessel_verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vessel_verbose.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
